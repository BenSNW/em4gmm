em4gmm
======

Fast C implementation of the clustering Expectation Maximization (EM) algorithm for estimating Gaussian Mixture Models (GMMs).

Introduction
------------
In statistics, an expectationâ€“maximization (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables.

For this reason EM is frequently used for data clustering, verification and identification of the speaker (biometrics), author profiling based on his documents, automatic document categorization, and many more applications.

Download
--------
* [Download the latest release of the source code on a zip file](https://github.com/juandavm/em4gmm/zipball/master).
* Clone the repository: `git clone git://github.com/juandavm/em4gmm.git`

Compiling
---------

On Mac Os X and Linux distributions you can simple use the make command on the system shell to compile it, and then sudo make install to install it on yout system (by default on /usr/bin). We recommend the use of the lastest version of GCC compiler (because the code generated by LLVM is, for now, much slower).

On Windows you can import all to a Dev-Cpp project (for instance) and compile from it. Then move the resulting executables to the directory where you want to use, and use it from the command line. Note that you will need to link the port of the pthreads library for your Windows compiler to success it.

Note that the default compilation makes this program work with 16 threads, if for any reason you want to change this value, feel free to edit the NUM_THREADS constant on the global.h file. Note that the minimum value of this constant must be 1.

Usage
-----

You can train a model using the gmmtrain utility on a feature train file (described below):

     ./gmmtrain <mixtures> <features> <model> [sigma]
          mixtures: number of gaussian mixtures
          features: feature file described before
          model: the place to save the resultant model
          sigma: optional stop criterion (usually 0.1-0.001)

Also, yo can obtain the score/log-probability of one feature test file (described below):

     ./gmmclass <features> <model> [world]
           features: feature file described before
           model: model used to classify the features
           world: optional world model to uniform data

The standard process is to train a model for each class, and then classify at the class with highest probability.

Speed Results
-------------

Compiling with GCC 4.7 on Mac Os X (2,66GHz Intel Core 2 Duo):

     Training with 100000 samples (10 dimensions) using 128 mixtures takes 5.81 seconds.
     Classify 100000 samples (10 dimensions) with the previous model takes 0.31 seconds.
     The same classification as before, but also using a world model takes 0.47 seconds.

Data Files
----------

The data files used by this software are very simple. They are plain text files of decimal numbers, with a header, and one line per sample vector. This is an example of a very short data file:

     11       4
     1025     7706     6830     5571     4169     2858     1809     1094      688      500      417
     1147     5755     6636     6234     4118     4593     2750     3649      774     1568     1104
      932     5381     5567     5175     3613     3499     2429     2536      652      913      337
      838     6401     5961     5277     4418     3468     2516     1644      921      391       74

On the header, the first number are the dimension and the second the number of samples. The sample's vectors can be integers or decimals (using "." as separator), and the dimensions must be space-separated. Also, you have an example of a data file on the dat directory of this project.

Issues and Bugs
---------------
Do you have a bug or a feature request? Do not worry, [open a new issue](https://github.com/juandavm/em4gmm/issues). But please, before opening any new issue, search on existing the yours in order to avoid duplicates. And thanks you for your contribution!

License
-------
     Expectation Maximization for Gaussian Mixture Models.
     Copyright (C) 2012-2013 Juan Daniel Valor Miro
     
     This program is free software; you can redistribute it and/or
     modify it under the terms of the GNU General Public License as
     published by the Free Software Foundation; either version 2 of
     the License, or (at your option) any later version.
     
     This program is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
     General Public License for more details.

